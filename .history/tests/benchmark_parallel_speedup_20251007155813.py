"""
Performance benchmark for parallel scene generation.

Measures actual speedup achieved by parallel execution vs sequential execution.
"""

import asyncio
import time
from unittest.mock import AsyncMock, MagicMock

from src.services.creative.script_generator import ScriptGenerator
from src.services.creative.character_voice_profiles import (
    DialogueLine,
    SceneDialogue,
)
from src.services.creative.stage_direction_models import (
    StageDirection,
    SceneStageDirections,
)


async def benchmark_scene_generation():
    """Run performance benchmark for parallel vs sequential scene generation."""
    
    print("\n" + "=" * 80)
    print("PARALLEL SCENE GENERATION PERFORMANCE BENCHMARK")
    print("=" * 80 + "\n")
    
    # Setup mock dependencies
    mock_dialogue_gen = AsyncMock()
    mock_stage_dir_gen = AsyncMock()
    mock_joke_opt = AsyncMock()
    mock_validator = MagicMock()
    
    # Mock dialogue generation (simulate 200ms API call)
    async def mock_generate_dialogue(*args, **kwargs):
        await asyncio.sleep(0.2)  # Simulate API latency
        return SceneDialogue(
            scene_number=kwargs.get('scene_number', 1),
            character_lines=[
                DialogueLine(
                    character_name="Luna",
                    text="This is a test line",
                    emotion="excited"
                )
            ]
        )
    mock_dialogue_gen.generate_dialogue = mock_generate_dialogue
    
    # Mock stage direction generation (simulate 100ms processing)
    async def mock_generate_stage_directions(*args, **kwargs):
        await asyncio.sleep(0.1)  # Simulate processing time
        return SceneStageDirections(
            scene_number=kwargs.get('scene_number', 1),
            directions=[
                StageDirection(
                    description="Character enters",
                    action_type="entrance"
                )
            ]
        )
    mock_stage_dir_gen.generate_stage_directions = (
        mock_generate_stage_directions
    )
    
    # Mock comedy optimization (simulate 150ms analysis)
    mock_comedy_analysis = MagicMock(
        analyzed_jokes=[],
        timing_analysis={},
        comedic_beats=[],
        improvement_suggestions=[]
    )
    mock_joke_opt.optimize_script_comedy = AsyncMock(
        return_value=mock_comedy_analysis
    )
    
    # Mock validation (instant)
    mock_validator.validate_script.return_value = (True, [])
    
    # Create minimal scene data structures
    num_scenes = 3
    scenes_metadata = [
        {"scene_number": i + 1, "description": f"Test scene {i + 1}"}
        for i in range(num_scenes)
    ]
    character_profiles = [{"name": "Luna"}]
    setting_info = {"type": "space_colony"}
    
    # Test 1: Sequential Execution (max_parallel_scenes=1)
    print("üìä TEST 1: Sequential Execution (max_parallel_scenes=1)")
    print("-" * 80)
    
    generator_sequential = ScriptGenerator(
        dialogue_generator=mock_dialogue_gen,
        stage_direction_generator=mock_stage_dir_gen,
        joke_optimizer=mock_joke_opt,
        validator=mock_validator,
        max_parallel_scenes=1  # Force sequential
    )
    
    start_time = time.time()
    # Generate scenes sequentially
    sequential_scenes = []
    for scene_meta in scenes_metadata:
        dialogue = await mock_dialogue_gen.generate_dialogue(
            scene_number=scene_meta["scene_number"]
        )
        stage_dirs = await mock_stage_dir_gen.generate_stage_directions(
            scene_number=scene_meta["scene_number"]
        )
        sequential_scenes.append({
            "dialogues": dialogue,
            "stage_directions": stage_dirs
        })
    sequential_time = time.time() - start_time
    
    print("Sequential execution completed")
    print(f"‚è±Ô∏è  Time: {sequential_time:.3f} seconds")
    print(f"üìù Scenes generated: {len(sequential_scenes)}")
    print()
    
    # Test 2: Parallel Execution (max_parallel_scenes=3)
    print("üìä TEST 2: Parallel Execution (max_parallel_scenes=3)")
    print("-" * 80)
    
    start_time = time.time()
    # Generate scenes in parallel using gather
    async def generate_scene(scene_meta):
        dialogue = await mock_dialogue_gen.generate_dialogue(
            scene_number=scene_meta["scene_number"]
        )
        stage_dirs = await mock_stage_dir_gen.generate_stage_directions(
            scene_number=scene_meta["scene_number"]
        )
        return {
            "dialogues": dialogue,
            "stage_directions": stage_dirs
        }
    
    parallel_scenes = await asyncio.gather(
        *[generate_scene(scene_meta) for scene_meta in scenes_metadata]
    )
    parallel_time = time.time() - start_time
    
    print("Parallel execution completed")
    print(f"‚è±Ô∏è  Time: {parallel_time:.3f} seconds")
    print(f"üìù Scenes generated: {len(parallel_scenes)}")
    print()
    
    # Calculate speedup
    speedup = sequential_time / parallel_time
    time_saved = sequential_time - parallel_time
    percent_faster = ((sequential_time - parallel_time) /
                      sequential_time) * 100
    
    # Results summary
    print("=" * 80)
    print("üìà PERFORMANCE RESULTS")
    print("=" * 80)
    print(f"Sequential time:      {sequential_time:.3f}s")
    print(f"Parallel time:        {parallel_time:.3f}s")
    print(f"Time saved:           {time_saved:.3f}s "
          f"({percent_faster:.1f}% faster)")
    print(f"Speedup factor:       {speedup:.2f}x")
    print()
    
    # Performance assessment
    print("=" * 80)
    print("‚úÖ PERFORMANCE ASSESSMENT")
    print("=" * 80)
    
    if speedup >= 2.0:
        print(f"üéâ EXCELLENT: Achieved {speedup:.2f}x speedup (target: 2x+)")
        print("   Parallel execution performing optimally!")
    elif speedup >= 1.5:
        print(f"‚úÖ GOOD: Achieved {speedup:.2f}x speedup (target: 2x+)")
        print("   Parallel execution working, minor overhead present")
    else:
        print(f"‚ö†Ô∏è  SUBOPTIMAL: Only {speedup:.2f}x speedup (target: 2x+)")
        print("   May need optimization or more parallelizable work")
    
    print()
    
    # Projected real-world performance
    print("=" * 80)
    print("üåç PROJECTED REAL-WORLD PERFORMANCE")
    print("=" * 80)
    print("Assuming realistic API latencies for full episode generation:")
    print()
    print("Dialogue Generation:    2-3 seconds per scene (LLM API)")
    print("Stage Direction:        1-2 seconds per scene (LLM API)")
    print("Comedy Optimization:    1-2 seconds (analysis)")
    print()
    
    # Calculate projected times for 3-scene episode
    realistic_scene_time = 5.0  # 3s dialogue + 2s directions = 5s per scene
    realistic_comedy_time = 1.5  # 1.5s comedy analysis
    
    realistic_sequential = (3 * realistic_scene_time) + realistic_comedy_time
    # Max of parallel scenes + comedy
    realistic_parallel = realistic_scene_time + realistic_comedy_time
    
    print(f"3-Scene Episode (Sequential):  ~{realistic_sequential:.0f}s "
          f"(~{realistic_sequential/60:.1f} minutes)")
    print(f"3-Scene Episode (Parallel):    ~{realistic_parallel:.0f}s "
          f"(~{realistic_parallel/60:.1f} minutes)")
    print(f"Expected Speedup:              "
          f"~{realistic_sequential/realistic_parallel:.1f}x")
    print()
    
    # Check against target
    target_time = 120  # 2 minutes
    if realistic_parallel <= target_time:
        print(f"‚úÖ MEETS TARGET: {realistic_parallel:.0f}s < "
              f"{target_time}s (2 min target)")
    else:
        print(f"‚ö†Ô∏è  EXCEEDS TARGET: {realistic_parallel:.0f}s > "
              f"{target_time}s (2 min target)")
    
    print()
    print("=" * 80)
    print("üéØ BENCHMARK COMPLETE")
    print("=" * 80)
    print()
    
    return {
        "sequential_time": sequential_time,
        "parallel_time": parallel_time,
        "speedup": speedup,
        "percent_faster": percent_faster,
        "meets_target": realistic_parallel <= target_time
    }


if __name__ == "__main__":
    results = asyncio.run(benchmark_scene_generation())

