"""\nGPT-4 Fallback Client - Backup AI engine when Claude unavailable.\n\nProvides identical interface to Claude client for seamless fallback.\n\nCopyright (c) 2025. All Rights Reserved. Patent Pending.\n"""\n\nfrom typing import Optional, List, Any\nimport os\nimport logging\nfrom openai import AsyncOpenAI\n\nfrom src.services.ai.base_client import BaseAIClient, AIResponse, AIClientError\n\nlogger = logging.getLogger(__name__)\n\n\nclass GPTClient(BaseAIClient):\n    \"\"\"\n    GPT-4 Turbo API client.\n    \n    Fallback AI engine activated when Claude is unavailable.\n    Provides identical interface for seamless switching.\n    \n    Pricing (as of 2025):\n    - Input: $10 per million tokens\n    - Output: $30 per million tokens\n    \n    Example:\n        >>> client = GPTClient(api_key=os.getenv('OPENAI_API_KEY'))\n        >>> response = await client.complete(\n        ...     prompt=\"Analyze this character\",\n        ...     system=\"You are an expert TV analyst\"\n        ... )\n    \"\"\"\n    \n    MODEL = \"gpt-4-turbo-preview\"\n    INPUT_COST_PER_MTOK = 10.00   # $10 per million input tokens\n    OUTPUT_COST_PER_MTOK = 30.00  # $30 per million output tokens\n    \n    def __init__(\n        self,\n        api_key: Optional[str] = None,\n        max_retries: int = 3,\n        timeout_seconds: int = 60\n    ):\n        \"\"\"Initialize GPT-4 client.\"\"\"\n        api_key = api_key or os.getenv('OPENAI_API_KEY')\n        if not api_key:\n            raise ValueError(\"OpenAI API key required\")\n        \n        super().__init__(\n            api_key=api_key,\n            max_retries=max_retries,\n            timeout_seconds=timeout_seconds\n        )\n        \n        self.client = AsyncOpenAI(api_key=api_key)\n        logger.info(f\"GPT-4 client initialized (model: {self.MODEL})\")\n    \n    async def _make_api_call(\n        self,\n        prompt: str,\n        system: Optional[str],\n        max_tokens: int,\n        temperature: float,\n        stop_sequences: Optional[List[str]]\n    ) -> Any:\n        \"\"\"Make API call to OpenAI.\"\"\"\n        messages = []\n        \n        if system:\n            messages.append({\"role\": \"system\", \"content\": system})\n        \n        messages.append({\"role\": \"user\", \"content\": prompt})\n        \n        params = {\n            \"model\": self.MODEL,\n            \"messages\": messages,\n            \"max_tokens\": max_tokens,\n            \"temperature\": temperature\n        }\n        \n        if stop_sequences:\n            params[\"stop\"] = stop_sequences\n        \n        response = await self.client.chat.completions.create(**params)\n        return response\n    \n    def _parse_response(self, raw_response: Any) -> AIResponse:\n        \"\"\"Parse OpenAI response.\"\"\"\n        content = raw_response.choices[0].message.content\n        input_tokens = raw_response.usage.prompt_tokens\n        output_tokens = raw_response.usage.completion_tokens\n        cost = self.calculate_cost(input_tokens, output_tokens)\n        \n        return AIResponse(\n            content=content,\n            model=raw_response.model,\n            input_tokens=input_tokens,\n            output_tokens=output_tokens,\n            cost=cost,\n            latency_ms=0.0,\n            metadata={\"id\": raw_response.id}\n        )\n